# russia_thinktank_bot.py
import json
import os
import re
import time
import logging
import requests
from bs4 import BeautifulSoup
from deep_translator import GoogleTranslator
import schedule
from supabase import create_client, Client

# ================== –ù–ê–°–¢–†–û–ô–ö–ò ==================
# üîë –¢–æ–∫–µ–Ω –±–µ—Ä–µ—Ç—Å—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
TELEGRAM_TOKEN = os.getenv('TELEGRAM_TOKEN')
if not TELEGRAM_TOKEN:
    raise ValueError("‚ùå –û—à–∏–±–∫–∞: –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è TELEGRAM_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")

CHANNEL_ID = os.getenv('CHANNEL_ID', "@time_n_John")

# üóÑÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Supabase
SUPABASE_URL = os.getenv('SUPABASE_URL')
SUPABASE_KEY = os.getenv('SUPABASE_KEY')
if not SUPABASE_URL or not SUPABASE_KEY:
    raise ValueError("‚ùå –û—à–∏–±–∫–∞: SUPABASE_URL –∏ SUPABASE_KEY –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã")

# –°–æ–∑–¥–∞–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Supabase
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
log = logging.getLogger(__name__)
log.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Supabase —É—Å–ø–µ—à–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")

# ================== –ò–°–¢–û–ß–ù–ò–ö–ò (–ö–ê–ù–ê–õ–´) ==================
SOURCES = [
    {"name": "Good Judgment", "url": "https://goodjudgment.com/feed/"},
    {"name": "Johns Hopkins", "url": "https://www.centerforhealthsecurity.org/feed/"},
    {"name": "Metaculus", "url": "https://www.metaculus.com/feed/"},
    {"name": "DNI Global Trends", "url": "https://www.dni.gov/index.php/feed"},
    {"name": "RAND Corporation", "url": "https://www.rand.org/rss.xml"},
    {"name": "World Economic Forum", "url": "https://www.weforum.org/rss"},
    {"name": "CSIS", "url": "https://www.csis.org/rss.xml"},
    {"name": "Atlantic Council", "url": "https://www.atlanticcouncil.org/feed/"},
    {"name": "Chatham House", "url": "https://www.chathamhouse.org/feed"},
    {"name": "The Economist", "url": "https://www.economist.com/world/rss.xml"},
    {"name": "Bloomberg", "url": "https://www.bloomberg.com/feed"},
    {"name": "Reuters Institute", "url": "https://reutersinstitute.politics.ox.ac.uk/rss.xml"},
    {"name": "Foreign Affairs", "url": "https://www.foreignaffairs.com/rss.xml"},
    {"name": "CFR", "url": "https://www.cfr.org/rss.xml"},
    {"name": "BBC Future", "url": "https://feeds.bbci.co.uk/future/rss.xml"},
    {"name": "Future Timeline", "url": "https://www.futuretimeline.net/feed/"},
    {"name": "Carnegie Endowment", "url": "https://carnegieendowment.org/rss/rss.xml"},
    {"name": "Bruegel", "url": "https://www.bruegel.org/rss"},
    {"name": "E3G", "url": "https://www.e3g.org/feed/"},
]

# ================== –§–ò–õ–¨–¢–†–´ (–ö–õ–Æ–ß–ï–í–´–ï –°–õ–û–í–ê) ==================
KEYWORDS = [
    # 1. –°–í–û –∏ –í–æ–π–Ω–∞
    r"\bsvo\b", r"\b—Å–ø–µ—Ü–æ–ø–µ—Ä–∞—Ü–∏—è\b", r"\bspecial military operation\b", 
    r"\b–≤–æ–π–Ω–∞\b", r"\bwar\b", r"\bconflict\b", r"\b–∫–æ–Ω—Ñ–ª–∏–∫—Ç\b", 
    r"\b–Ω–∞—Å—Ç—É–ø–ª–µ–Ω–∏–µ\b", r"\boffensive\b", r"\b–∞—Ç–∞–∫–∞\b", r"\battack\b", 
    r"\b—É–¥–∞—Ä\b", r"\bstrike\b", r"\b–æ–±—Å—Ç—Ä–µ–ª\b", r"\bshelling\b", 
    r"\b–¥—Ä–æ–Ω\b", r"\bdrone\b", r"\bmissile\b", r"\b—Ä–∞–∫–µ—Ç–∞\b", 
    r"\b—ç—Å–∫–∞–ª–∞—Ü–∏—è\b", r"\bescalation\b", r"\b–º–æ–±–∏–ª–∏–∑–∞—Ü–∏—è\b", r"\bmobilization\b", 
    r"\b—Ñ—Ä–æ–Ω—Ç\b", r"\bfrontline\b", r"\b–∑–∞—Ö–≤–∞—Ç\b", r"\bcapture\b", 
    r"\b–æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ\b", r"\bliberation\b", r"\b–±–æ–π\b", r"\bbattle\b", 
    r"\b–ø–æ—Ç–µ—Ä–∏\b", r"\bcasualties\b", r"\b–ø–æ–≥–∏–±\b", r"\bkilled\b", 
    r"\b—Ä–∞–Ω–µ–Ω\b", r"\binjured\b", r"\b–ø–ª–µ–Ω–Ω—ã–π\b", r"\bprisoner of war\b", 
    r"\b–ø–µ—Ä–µ–≥–æ–≤–æ—Ä—ã\b", r"\btalks\b", r"\b–ø–µ—Ä–µ–º–∏—Ä–∏–µ\b", r"\bceasefire\b", 
    r"\b—Å–∞–Ω–∫—Ü–∏–∏\b", r"\bsanctions\b", r"\b–æ—Ä—É–∂–∏–µ\b", r"\bweapons\b", 
    r"\b–ø–æ—Å—Ç–∞–≤–∫–∏\b", r"\bsupplies\b", r"\bhimars\b", r"\batacms\b", 
    r"\bhour ago\b", r"\b—á–∞—Å –Ω–∞–∑–∞–¥\b", r"\bminutos atr√°s\b", r"\bÂ∞èÊó∂Ââç\b",

    # 2. –ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞ (—Ç–æ–ø-20 + CBDC, DeFi, —Ä–µ–≥—É–ª—è—Ü–∏—è)
    r"\bbitcoin\b", r"\bbtc\b", r"\b–±–∏—Ç–∫–æ–∏–Ω\b", r"\bÊØîÁâπÂ∏Å\b", 
    r"\bethereum\b", r"\beth\b", r"\b—ç—Ñ–∏—Ä\b", r"\b‰ª•Â§™Âùä\b", 
    r"\bbinance coin\b", r"\bbnb\b", r"\busdt\b", r"\btether\b", 
    r"\bxrp\b", r"\bripple\b", r"\bcardano\b", r"\bada\b", 
    r"\bsolana\b", r"\bsol\b", r"\bdoge\b", r"\bdogecoin\b", 
    r"\bavalanche\b", r"\bavax\b", r"\bpolkadot\b", r"\bdot\b", 
    r"\bchainlink\b", r"\blink\b", r"\btron\b", r"\btrx\b", 
    r"\bcbdc\b", r"\bcentral bank digital currency\b", r"\b—Ü–∏—Ñ—Ä–æ–≤–æ–π —Ä—É–±–ª—å\b", 
    r"\bdigital yuan\b", r"\beuro digital\b", r"\bdefi\b", r"\b–¥–µ—Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å—ã\b", 
    r"\bnft\b", r"\bnon-fungible token\b", r"\bsec\b", r"\b—Ü–± —Ä—Ñ\b", 
    r"\b—Ä–µ–≥—É–ª—è—Ü–∏—è\b", r"\bregulation\b", r"\b–∑–∞–ø—Ä–µ—Ç\b", r"\bban\b", 
    r"\b–º–∞–π–Ω–∏–Ω–≥\b", r"\bmining\b", r"\bhalving\b", r"\b—Ö–∞–ª–≤–∏–Ω–≥\b", 
    r"\b–≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å\b", r"\bvolatility\b", r"\bcrash\b", r"\b–∫—Ä–∞—Ö\b", 
    r"\bhour ago\b", r"\b—á–∞—Å –Ω–∞–∑–∞–¥\b", r"\bÂàöÂàö\b", r"\bÿØŸÇÿßÿ¶ŸÇ ŸÖÿ∂ÿ™\b",

    # 3. –ü–∞–Ω–¥–µ–º–∏—è –∏ –±–æ–ª–µ–∑–Ω–∏ (–≤–∫–ª—é—á–∞—è –±–∏–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å)
    r"\bpandemic\b", r"\b–ø–∞–Ω–¥–µ–º–∏—è\b", r"\bÁñ´ÊÉÖ\b", r"\bÿ¨ÿßÿ¶ÿ≠ÿ©\b", 
    r"\boutbreak\b", r"\b–≤—Å–ø—ã—à–∫–∞\b", r"\b—ç–ø–∏–¥–µ–º–∏—è\b", r"\bepidemic\b", 
    r"\bvirus\b", r"\b–≤–∏—Ä—É—Å\b", r"\b–≤–∏—Ä—É—Å—ã\b", r"\bÂèòÂºÇÊ†™\b", 
    r"\bvaccine\b", r"\b–≤–∞–∫—Ü–∏–Ω–∞\b", r"\bÁñ´Ëãó\b", r"\bŸÑŸÇÿßÿ≠\b", 
    r"\bbooster\b", r"\b–±—É—Å—Ç–µ—Ä\b", r"\b—Ä–µ–≤–∞–∫—Ü–∏–Ω–∞—Ü–∏—è\b", 
    r"\bquarantine\b", r"\b–∫–∞—Ä–∞–Ω—Ç–∏–Ω\b", r"\bÈöîÁ¶ª\b", r"\bÿ≠ÿ¨ÿ± ÿµÿ≠Ÿä\b", 
    r"\blockdown\b", r"\b–ª–æ–∫–¥–∞—É–Ω\b", r"\bÂ∞ÅÈîÅ\b", 
    r"\bmutation\b", r"\b–º—É—Ç–∞—Ü–∏—è\b", r"\bÂèòÂºÇ\b", 
    r"\bstrain\b", r"\b—à—Ç–∞–º–º\b", r"\bomicron\b", r"\bdelta\b", 
    r"\bbiosafety\b", r"\b–±–∏–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å\b", r"\bÁîüÁâ©ÂÆâÂÖ®\b", 
    r"\blab leak\b", r"\b–ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —É—Ç–µ—á–∫–∞\b", r"\bÂÆûÈ™åÂÆ§Ê≥ÑÊºè\b", 
    r"\bgain of function\b", r"\b—É—Å–∏–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏\b", 
    r"\bwho\b", r"\b–≤–æ–∑\b", r"\bcdc\b", r"\b—Ä–æ—Å–ø–æ—Ç—Ä–µ–±–Ω–∞–¥–∑–æ—Ä\b", 
    r"\binfection rate\b", r"\b–∑–∞—Ä–∞–∑–Ω–æ—Å—Ç—å\b", r"\bÊ≠ª‰∫°Áéá\b", 
    r"\bhospitalization\b", r"\b–≥–æ—Å–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è\b", 
    r"\bhour ago\b", r"\b—á–∞—Å –Ω–∞–∑–∞–¥\b", r"\bŸÇÿ®ŸÑ ÿ≥ÿßÿπÿßÿ™\b", r"\bÂàöÂàöÊä•Âëä\b"
]

MAX_PER_RUN = 10
CHECK_INTERVAL = int(os.getenv('CHECK_INTERVAL', 15))

# ================== –õ–û–ì–ò–†–û–í–ê–ù–ò–ï ==================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler("bot.log", encoding="utf-8"),
        logging.StreamHandler()
    ]
)

# ================== –ó–ê–ì–û–õ–û–í–ö–ò ==================
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:125.0) Gecko/20100101 Firefox/125.0',
    'Accept': 'application/rss+xml, application/xml;q=0.9, */*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'DNT': '1',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1',
}

# ================== –£–¢–ò–õ–ò–¢–´ ==================
def is_article_published(url: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –±—ã–ª–∞ –ª–∏ —Å—Ç–∞—Ç—å—è —É–∂–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞"""
    try:
        response = supabase.table('news_articles').select('id').eq('url', url).execute()
        return bool(response.data)
    except Exception as e:
        log.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {e}")
        return False

def get_article_category(title: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Å—Ç–∞—Ç—å–∏"""
    low = title.lower()
    if re.search(r"svo|—Å–ø–µ—Ü–æ–ø–µ—Ä–∞—Ü–∏—è|–≤–æ–π–Ω–∞|war|conflict|–∫–æ–Ω—Ñ–ª–∏–∫—Ç|–Ω–∞—Å—Ç—É–ø–ª–µ–Ω–∏–µ|offensive", low):
        return "SVO"
    if re.search(r"bitcoin|btc|ethereum|eth|–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞|crypto|—Ü–∏—Ñ—Ä–æ–≤–æ–π —Ä—É–±–ª—å", low):
        return "Crypto"
    if re.search(r"pandemic|–ø–∞–Ω–¥–µ–º–∏—è|–≤–∏—Ä—É—Å|virus|–≤–∞–∫—Ü–∏–Ω–∞|vaccine|–±—É—Å—Ç–µ—Ä|booster", low):
        return "Pandemic"
    return "Other"

def save_article(title: str, url: str, description: str, pub_date: str, source_name: str):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∞—Ç—å—é –≤ Supabase"""
    category = get_article_category(title)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞ –ª–∏ —É–∂–µ —Å—Ç–∞—Ç—å—è
    if is_article_published(url):
        log.info(f"‚ÑπÔ∏è –°—Ç–∞—Ç—å—è —É–∂–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞: {url}")
        return False
    
    try:
        data = {
            'title': title,
            'url': url,
            'description': description,
            'pub_date': pub_date,
            'source_name': source_name,
            'category': category
        }
        
        supabase.table('news_articles').insert(data).execute()
        log.info(f"‚úÖ –°—Ç–∞—Ç—å—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ –±–∞–∑—É: {url}")
        return True
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏: {e}")
        return False

def format_message(source_name: str, title: str, link: str, description: str) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —Ç—Ä–µ–±—É–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ"""
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –∫–∞–∫ –∫—Ä–∞—Ç–∫–∏–π –ª–∏—Ç
    sentences = [s.strip() for s in description.split('. ') if s.strip()]
    brief = ". ".join(sentences[:2]) + "." if sentences else ""
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ —Ç—Ä–µ–±—É–µ–º–æ–º—É —à–∞–±–ª–æ–Ω—É
    return f"*{source_name}*:\n\n{title}\n\n{brief}\n\n–ò—Å—Ç–æ—á–Ω–∏–∫: {link}"

def send_to_telegram(text: str) -> bool:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ Telegram"""
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {
        "chat_id": CHANNEL_ID,
        "text": text,
        "parse_mode": "Markdown",
        "disable_web_page_preview": True,
    }
    try:
        r = requests.post(url, data=payload, timeout=15)
        r.raise_for_status()
        log.info("‚úÖ –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ Telegram")
        return True
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {e}")
        return False

def clean_text(t: str) -> str:
    """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤ –∏ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤"""
    return re.sub(r"\s+", " ", t).strip()

def translate_to_russian(text: str) -> str:
    """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫"""
    try:
        return GoogleTranslator(source='auto', target='ru').translate(text)
    except Exception as e:
        log.warning(f"‚ö†Ô∏è –ü–µ—Ä–µ–≤–æ–¥ –Ω–µ —É–¥–∞–ª—Å—è: {e}")
        return text

# ================== –ü–ê–†–°–ò–ù–ì RSS ==================
def fetch_rss_news() -> list:
    """–ü–æ–ª—É—á–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ RSS-–ª–µ–Ω—Ç"""
    result = []
    session = requests.Session()
    session.headers.update(HEADERS)

    for src in SOURCES:
        if len(result) >= MAX_PER_RUN:
            break
        try:
            log.info(f"üåê –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º: {src['name']}")
            resp = session.get(src["url"].strip(), timeout=30)
            
            if resp.status_code != 200:
                log.warning(f"{src['name']}: HTTP {resp.status_code}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue

            # –ü—Ä–æ–≤–µ—Ä–∫–∞: –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ª–∏ —ç—Ç–æ XML?
            content = resp.text.strip()
            if not (content.startswith('<?xml') or '<rss' in content[:500] or '<feed' in content[:500]):
                log.warning(f"{src['name']}: –ü–æ–ª—É—á–µ–Ω –Ω–µ XML-–∫–æ–Ω—Ç–µ–Ω—Ç. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                continue

            soup = BeautifulSoup(resp.content, "xml")
            for item in soup.find_all("item"):
                if len(result) >= MAX_PER_RUN:
                    break

                title_tag = item.find("title")
                link_tag = item.find("link") or item.find("guid")
                description_tag = item.find("description") or item.find("summary")
                pub_date_tag = item.find("pubDate")

                if not title_tag or not link_tag:
                    continue

                title = clean_text(title_tag.get_text())
                link = clean_text(link_tag.get_text() if hasattr(link_tag, 'get_text') else link_tag.text)
                description = clean_text(description_tag.get_text()) if description_tag else ""
                pub_date = clean_text(pub_date_tag.get_text()) if pub_date_tag else ""

                if not title or not link:
                    continue

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
                if not any(re.search(kw, title, re.IGNORECASE) for kw in KEYWORDS):
                    continue

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –±—ã–ª–∞ –ª–∏ —Å—Ç–∞—Ç—å—è —É–∂–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞
                if is_article_published(link):
                    continue

                ru_title = translate_to_russian(title)
                description_ru = translate_to_russian(description) if description else ""
                msg = format_message(src['name'], ru_title, link, description_ru)
                
                if len(msg) > 4000:  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ Telegram
                    msg = msg[:3997] + "..."
                    
                result.append({
                    "msg": msg, 
                    "link": link,
                    "title": title,
                    "description": description,
                    "pub_date": pub_date,
                    "source_name": src['name']
                })

        except Exception as e:
            log.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {src['name']}: {e}")

    return result

# ================== –û–°–ù–û–í–ù–û–ô –¶–ò–ö–õ ==================
def job():
    log.info("üîÑ –ó–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π...")
    news = fetch_rss_news()
    if not news:
        log.info("üì≠ –ù–æ–≤–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        return

    for item in news:
        if send_to_telegram(item["msg"]):
            save_article(
                item["title"],
                item["link"],
                item["description"],
                item["pub_date"],
                item["source_name"]
            )
        time.sleep(1.5)

# ================== –ó–ê–ü–£–°–ö ==================
if __name__ == "__main__":
    log.info(f"üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥—ã–µ {CHECK_INTERVAL} –º–∏–Ω—É—Ç.")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Supabase
    try:
        response = supabase.table('news_articles').select('id').limit(1).execute()
        log.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Supabase –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Supabase: {e}")
        raise SystemExit("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Supabase")
    
    job()  # ‚úÖ –ü–µ—Ä–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞
    
    schedule.every(CHECK_INTERVAL).minutes.do(job)

    while True:
        schedule.run_pending()
        time.sleep(1)
